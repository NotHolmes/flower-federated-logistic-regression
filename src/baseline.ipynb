{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 30)\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = utils.load_dataset(\"../dataset/train.csv\")\n",
    "X_test, y_test = utils.load_dataset(\"../dataset/test.csv\")\n",
    "# X_val, y_val = utils.load_dataset(\"../dataset/validation.csv\")\n",
    "X_train, X_test = utils.scale_data(X_train, X_test)\n",
    "# X_val, _ = utils.scale_data(X_val, X_val)\n",
    "\n",
    "combined_X = pd.concat([X_train, X_test])\n",
    "combined_y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pred_report(X_train, y_train, X_test):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_X, combined_y, test_size=0.1, shuffle=True, random_state=None)\n",
    "    y_pred = fit_pred_report(X_train, y_train, X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.6455840455840456, 'recall': 0.4349328214971209, 'f1-score': 0.5197247706422019, 'support': 2605}, '1': {'precision': 0.6183798053126547, 'recall': 0.7750206782464847, 'f1-score': 0.6878957511241626, 'support': 4836}, '2': {'precision': 0.48817567567567566, 'recall': 0.3707504810776139, 'f1-score': 0.4214363835216916, 'support': 1559}, 'accuracy': 0.6065555555555555, 'macro avg': {'precision': 0.5840465088574586, 'recall': 0.5269013269404065, 'f1-score': 0.543018968429352, 'support': 9000}, 'weighted avg': {'precision': 0.6036996728463128, 'recall': 0.6065555555555555, 'f1-score': 0.593062911318856, 'support': 9000}}\n",
      "{'0': {'precision': 0.6404365307294658, 'recall': 0.4315015479876161, 'f1-score': 0.5156069364161849, 'support': 2584}, '1': {'precision': 0.6102598267821452, 'recall': 0.7686175791902664, 'f1-score': 0.6803453718317705, 'support': 4767}, '2': {'precision': 0.501195219123506, 'recall': 0.38144329896907214, 'f1-score': 0.43319559228650134, 'support': 1649}, 'accuracy': 0.6008888888888889, 'macro avg': {'precision': 0.5839638588783723, 'recall': 0.5271874753823181, 'f1-score': 0.5430493001781522, 'support': 9000}, 'weighted avg': {'precision': 0.5989408340011207, 'recall': 0.6008888888888889, 'f1-score': 0.5877638047668792, 'support': 9000}}\n",
      "{'0': {'precision': 0.6334639059876889, 'recall': 0.43355036384527, 'f1-score': 0.5147794452023646, 'support': 2611}, '1': {'precision': 0.6103185136031851, 'recall': 0.7720881427072402, 'f1-score': 0.6817381636245715, 'support': 4765}, '2': {'precision': 0.5113924050632911, 'recall': 0.3731527093596059, 'f1-score': 0.4314702741189035, 'support': 1624}, 'accuracy': 0.6018888888888889, 'macro avg': {'precision': 0.5850582748847217, 'recall': 0.526263738637372, 'f1-score': 0.5426626276486132, 'support': 9000}, 'weighted avg': {'precision': 0.5991825824084243, 'recall': 0.6018888888888889, 'f1-score': 0.5881421340292841, 'support': 9000}}\n",
      "{'0': {'precision': 0.6146841206602163, 'recall': 0.4163454124903624, 'f1-score': 0.4964376005515974, 'support': 2594}, '1': {'precision': 0.6146635420154001, 'recall': 0.7589913187267466, 'f1-score': 0.679245283018868, 'support': 4838}, '2': {'precision': 0.49014972419227737, 'recall': 0.39668367346938777, 'f1-score': 0.43849136411702505, 'support': 1568}, 'accuracy': 0.5971111111111111, 'macro avg': {'precision': 0.5731657956226313, 'recall': 0.5240068015621656, 'f1-score': 0.5380580825624968, 'support': 9000}, 'weighted avg': {'precision': 0.592976399199622, 'recall': 0.5971111111111111, 'f1-score': 0.5846113637790691, 'support': 9000}}\n",
      "{'0': {'precision': 0.6470588235294118, 'recall': 0.41413753361505956, 'f1-score': 0.5050363082689154, 'support': 2603}, '1': {'precision': 0.6142951251646904, 'recall': 0.779030910609858, 'f1-score': 0.6869244935543278, 'support': 4788}, '2': {'precision': 0.5134706814580031, 'recall': 0.4027346177750155, 'f1-score': 0.45141065830721, 'support': 1609}, 'accuracy': 0.6062222222222222, 'macro avg': {'precision': 0.5916082100507017, 'recall': 0.531967687333311, 'f1-score': 0.5477904867101511, 'support': 9000}, 'weighted avg': {'precision': 0.6057459448223916, 'recall': 0.6062222222222222, 'f1-score': 0.5922137483087121, 'support': 9000}}\n",
      "{'0': {'precision': 0.6394285714285715, 'recall': 0.42972350230414746, 'f1-score': 0.5140101056499771, 'support': 2604}, '1': {'precision': 0.6176568204447395, 'recall': 0.7726800913431596, 'f1-score': 0.6865258692243844, 'support': 4817}, '2': {'precision': 0.49754901960784315, 'recall': 0.38568714376187463, 'f1-score': 0.43453442739921516, 'support': 1579}, 'accuracy': 0.6055555555555555, 'macro avg': {'precision': 0.5848781371603847, 'recall': 0.529363579136394, 'f1-score': 0.5450234674245256, 'support': 9000}, 'weighted avg': {'precision': 0.6028838673381216, 'recall': 0.6055555555555555, 'f1-score': 0.5924008097810846, 'support': 9000}}\n",
      "{'0': {'precision': 0.6380728554641598, 'recall': 0.4224037339556593, 'f1-score': 0.5083079803416803, 'support': 2571}, '1': {'precision': 0.6189672629092137, 'recall': 0.7628951747088186, 'f1-score': 0.6834358114402832, 'support': 4808}, '2': {'precision': 0.5080174927113703, 'recall': 0.4299814929056138, 'f1-score': 0.4657534246575343, 'support': 1621}, 'accuracy': 0.6056666666666667, 'macro avg': {'precision': 0.588352537028248, 'recall': 0.5384268005233639, 'f1-score': 0.5524990721464993, 'support': 9000}, 'weighted avg': {'precision': 0.6044418074612206, 'recall': 0.6056666666666667, 'f1-score': 0.5942006111370227, 'support': 9000}}\n",
      "{'0': {'precision': 0.6471610660486674, 'recall': 0.42994611239414937, 'f1-score': 0.5166512488436633, 'support': 2598}, '1': {'precision': 0.6209236881311041, 'recall': 0.7816211710773078, 'f1-score': 0.6920664206642068, 'support': 4799}, '2': {'precision': 0.5141930251419302, 'recall': 0.39550842170929507, 'f1-score': 0.44710860366713684, 'support': 1603}, 'accuracy': 0.6113333333333333, 'macro avg': {'precision': 0.594092593107234, 'recall': 0.5356919017269174, 'f1-score': 0.5519420910583356, 'support': 9000}, 'weighted avg': {'precision': 0.6094876275820135, 'recall': 0.6113333333333333, 'f1-score': 0.5978001987713095, 'support': 9000}}\n",
      "{'0': {'precision': 0.6482954545454546, 'recall': 0.43137996219281666, 'f1-score': 0.5180476730987514, 'support': 2645}, '1': {'precision': 0.6112314614230961, 'recall': 0.7786032689450223, 'f1-score': 0.6848394324122479, 'support': 4711}, '2': {'precision': 0.54317998385795, 'recall': 0.409367396593674, 'f1-score': 0.466874783211932, 'support': 1644}, 'accuracy': 0.6091111111111112, 'macro avg': {'precision': 0.6009022999421668, 'recall': 0.539783542577171, 'f1-score': 0.5565872962409771, 'support': 9000}, 'weighted avg': {'precision': 0.6096934206110447, 'recall': 0.6091111111111112, 'f1-score': 0.5960063116711904, 'support': 9000}}\n",
      "{'0': {'precision': 0.6304985337243402, 'recall': 0.4223968565815324, 'f1-score': 0.5058823529411764, 'support': 2545}, '1': {'precision': 0.6180278884462151, 'recall': 0.7708074534161491, 'f1-score': 0.6860143725815367, 'support': 4830}, '2': {'precision': 0.5027537372147916, 'recall': 0.3932307692307692, 'f1-score': 0.44129834254143646, 'support': 1625}, 'accuracy': 0.6041111111111112, 'macro avg': {'precision': 0.583760053128449, 'recall': 0.5288116930761503, 'f1-score': 0.5443983560213833, 'support': 9000}, 'weighted avg': {'precision': 0.6007409213886334, 'recall': 0.6041111111111112, 'f1-score': 0.5908922016037723, 'support': 9000}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score (0)</th>\n",
       "      <th>F1 Score (1)</th>\n",
       "      <th>F1 Score (2)</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Precision (2)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>Recall (2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline #1</td>\n",
       "      <td>60.655556</td>\n",
       "      <td>51.972477</td>\n",
       "      <td>68.789575</td>\n",
       "      <td>42.143638</td>\n",
       "      <td>64.558405</td>\n",
       "      <td>61.837981</td>\n",
       "      <td>48.817568</td>\n",
       "      <td>43.493282</td>\n",
       "      <td>77.502068</td>\n",
       "      <td>37.075048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline #2</td>\n",
       "      <td>60.088889</td>\n",
       "      <td>51.560694</td>\n",
       "      <td>68.034537</td>\n",
       "      <td>43.319559</td>\n",
       "      <td>64.043653</td>\n",
       "      <td>61.025983</td>\n",
       "      <td>50.119522</td>\n",
       "      <td>43.150155</td>\n",
       "      <td>76.861758</td>\n",
       "      <td>38.144330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline #3</td>\n",
       "      <td>60.188889</td>\n",
       "      <td>51.477945</td>\n",
       "      <td>68.173816</td>\n",
       "      <td>43.147027</td>\n",
       "      <td>63.346391</td>\n",
       "      <td>61.031851</td>\n",
       "      <td>51.139241</td>\n",
       "      <td>43.355036</td>\n",
       "      <td>77.208814</td>\n",
       "      <td>37.315271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline #4</td>\n",
       "      <td>59.711111</td>\n",
       "      <td>49.643760</td>\n",
       "      <td>67.924528</td>\n",
       "      <td>43.849136</td>\n",
       "      <td>61.468412</td>\n",
       "      <td>61.466354</td>\n",
       "      <td>49.014972</td>\n",
       "      <td>41.634541</td>\n",
       "      <td>75.899132</td>\n",
       "      <td>39.668367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline #5</td>\n",
       "      <td>60.622222</td>\n",
       "      <td>50.503631</td>\n",
       "      <td>68.692449</td>\n",
       "      <td>45.141066</td>\n",
       "      <td>64.705882</td>\n",
       "      <td>61.429513</td>\n",
       "      <td>51.347068</td>\n",
       "      <td>41.413753</td>\n",
       "      <td>77.903091</td>\n",
       "      <td>40.273462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline #6</td>\n",
       "      <td>60.555556</td>\n",
       "      <td>51.401011</td>\n",
       "      <td>68.652587</td>\n",
       "      <td>43.453443</td>\n",
       "      <td>63.942857</td>\n",
       "      <td>61.765682</td>\n",
       "      <td>49.754902</td>\n",
       "      <td>42.972350</td>\n",
       "      <td>77.268009</td>\n",
       "      <td>38.568714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline #7</td>\n",
       "      <td>60.566667</td>\n",
       "      <td>50.830798</td>\n",
       "      <td>68.343581</td>\n",
       "      <td>46.575342</td>\n",
       "      <td>63.807286</td>\n",
       "      <td>61.896726</td>\n",
       "      <td>50.801749</td>\n",
       "      <td>42.240373</td>\n",
       "      <td>76.289517</td>\n",
       "      <td>42.998149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baseline #8</td>\n",
       "      <td>61.133333</td>\n",
       "      <td>51.665125</td>\n",
       "      <td>69.206642</td>\n",
       "      <td>44.710860</td>\n",
       "      <td>64.716107</td>\n",
       "      <td>62.092369</td>\n",
       "      <td>51.419303</td>\n",
       "      <td>42.994611</td>\n",
       "      <td>78.162117</td>\n",
       "      <td>39.550842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>baseline #9</td>\n",
       "      <td>60.911111</td>\n",
       "      <td>51.804767</td>\n",
       "      <td>68.483943</td>\n",
       "      <td>46.687478</td>\n",
       "      <td>64.829545</td>\n",
       "      <td>61.123146</td>\n",
       "      <td>54.317998</td>\n",
       "      <td>43.137996</td>\n",
       "      <td>77.860327</td>\n",
       "      <td>40.936740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>baseline #10</td>\n",
       "      <td>60.411111</td>\n",
       "      <td>50.588235</td>\n",
       "      <td>68.601437</td>\n",
       "      <td>44.129834</td>\n",
       "      <td>63.049853</td>\n",
       "      <td>61.802789</td>\n",
       "      <td>50.275374</td>\n",
       "      <td>42.239686</td>\n",
       "      <td>77.080745</td>\n",
       "      <td>39.323077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Algorithm   Accuracy  F1 Score (0)  F1 Score (1)  F1 Score (2)  \\\n",
       "0   baseline #1  60.655556     51.972477     68.789575     42.143638   \n",
       "1   baseline #2  60.088889     51.560694     68.034537     43.319559   \n",
       "2   baseline #3  60.188889     51.477945     68.173816     43.147027   \n",
       "3   baseline #4  59.711111     49.643760     67.924528     43.849136   \n",
       "4   baseline #5  60.622222     50.503631     68.692449     45.141066   \n",
       "5   baseline #6  60.555556     51.401011     68.652587     43.453443   \n",
       "6   baseline #7  60.566667     50.830798     68.343581     46.575342   \n",
       "7   baseline #8  61.133333     51.665125     69.206642     44.710860   \n",
       "8   baseline #9  60.911111     51.804767     68.483943     46.687478   \n",
       "9  baseline #10  60.411111     50.588235     68.601437     44.129834   \n",
       "\n",
       "   Precision (0)  Precision (1)  Precision (2)  Recall (0)  Recall (1)  \\\n",
       "0      64.558405      61.837981      48.817568   43.493282   77.502068   \n",
       "1      64.043653      61.025983      50.119522   43.150155   76.861758   \n",
       "2      63.346391      61.031851      51.139241   43.355036   77.208814   \n",
       "3      61.468412      61.466354      49.014972   41.634541   75.899132   \n",
       "4      64.705882      61.429513      51.347068   41.413753   77.903091   \n",
       "5      63.942857      61.765682      49.754902   42.972350   77.268009   \n",
       "6      63.807286      61.896726      50.801749   42.240373   76.289517   \n",
       "7      64.716107      62.092369      51.419303   42.994611   78.162117   \n",
       "8      64.829545      61.123146      54.317998   43.137996   77.860327   \n",
       "9      63.049853      61.802789      50.275374   42.239686   77.080745   \n",
       "\n",
       "   Recall (2)  \n",
       "0   37.075048  \n",
       "1   38.144330  \n",
       "2   37.315271  \n",
       "3   39.668367  \n",
       "4   40.273462  \n",
       "5   38.568714  \n",
       "6   42.998149  \n",
       "7   39.550842  \n",
       "8   40.936740  \n",
       "9   39.323077  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "iter_num = 0\n",
    "for item in reports:\n",
    "    print(item)\n",
    "    iter_num = iter_num + 1 if iter_num is not None else 1\n",
    "    name = \"baseline #\" + str(iter_num)\n",
    "    accuracy = item['accuracy'] * 100\n",
    "    f1_0 = item['0']['f1-score'] * 100\n",
    "    f1_1 = item['1']['f1-score'] * 100\n",
    "    f1_2 = item['2']['f1-score'] * 100\n",
    "    precision_0 = item['0']['precision'] * 100\n",
    "    precision_1 = item['1']['precision'] * 100\n",
    "    precision_2 = item['2']['precision'] * 100\n",
    "    recall_0 = item['0']['recall'] * 100\n",
    "    recall_1 = item['1']['recall'] * 100\n",
    "    recall_2 = item['2']['recall'] * 100\n",
    "    data.append([name, accuracy, f1_0, f1_1, f1_2, precision_0, precision_1, precision_2, recall_0, recall_1, recall_2])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Algorithm\", \"Accuracy\", \"F1 Score (0)\", \"F1 Score (1)\", \"F1 Score (2)\", \"Precision (0)\", \"Precision (1)\", \"Precision (2)\", \"Recall (0)\", \"Recall (1)\", \"Recall (2)\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"../logs/data/baseline_result.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
