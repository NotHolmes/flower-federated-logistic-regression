{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read your data (assuming it's in a file named 'data.txt')\n",
    "with open('logs.txt', 'r') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# Step 2: Split the data into sections\n",
    "sections = text_data.split('logs/experiment/fedkrum_log.txt:')\n",
    "sections = sections[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      round      loss  exp_num  accuracy\n",
      "0         0  1.098612        1  0.289400\n",
      "1         1  0.944096        1  0.570800\n",
      "2         2  0.847279        1  0.596400\n",
      "3         3  0.840964        1  0.594300\n",
      "4         4  0.833092        1  0.601700\n",
      "...     ...       ...      ...       ...\n",
      "1005     96  0.606800       10  0.815866\n",
      "1006     97  0.609700       10  0.814413\n",
      "1007     98  0.607000       10  0.814664\n",
      "1008     99  0.606400       10  0.814116\n",
      "1009    100  0.610000       10  0.815246\n",
      "\n",
      "[1010 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Extract data using regular expressions\n",
    "loss_pattern = r'\\(([\\d]+), ([\\d.]+)\\)'\n",
    "metric_pattern = r'\\(([\\d]+), ([\\d.]+)\\)'\n",
    "\n",
    "data = []\n",
    "for i in range(10):\n",
    "    losses_section = sections[i]\n",
    "    metrics_section = sections[i+1]\n",
    "\n",
    "    losses = re.findall(loss_pattern, losses_section)\n",
    "    metrics = re.findall(metric_pattern, metrics_section)\n",
    "\n",
    "    df = pd.DataFrame(losses, columns=['round', 'loss'])\n",
    "    df['round'] = df['round'].astype(int)\n",
    "    df['loss'] = df['loss'].astype(float)\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics, columns=['round', 'accuracy'])\n",
    "    metrics_df['round'] = metrics_df['round'].astype(int)\n",
    "    metrics_df['accuracy'] = metrics_df['accuracy'].astype(float)\n",
    "\n",
    "    df['exp_num'] = i+1\n",
    "    metrics_df['exp_num'] = i+1\n",
    "\n",
    "    merged_df = pd.merge(df, metrics_df, on=['round', 'exp_num'])\n",
    "\n",
    "    data.append(merged_df)\n",
    "\n",
    "# Step 4: Concatenate the dataframes\n",
    "df = pd.concat(data, ignore_index=True)\n",
    "\n",
    "# Step 5: Now you have your data in a single dataframe!\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('fedkrum_log.xlsx', columns=['exp_num', 'round', 'loss', 'accuracy'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
